# ==============================================================================
# Performance Tuning: The 5 S Framework
# ==============================================================================
# This file implements performance tuning best practices using the "5 S" framework:
# 1. SPILL (Memory Management)
# 2. SKEW (Data Distribution)
# 3. SHUFFLE (Network Optimization)
# 4. STORAGE (I/O Optimization)
# 5. SERIALIZATION (CPU Optimization)

# ==============================================================================
# 1. SPILL - Memory Management Optimization
# ==============================================================================

resource "databricks_cluster_policy" "memory_optimized" {
  name = "Memory Optimized - Anti-Spill Policy"

  definition = jsonencode({
    "spark_conf.spark.memory.fraction" : {
      "type" : "fixed",
      "value" : "0.8"
    },
    "spark_conf.spark.memory.storageFraction" : {
      "type" : "fixed",
      "value" : "0.3"
    },
    "spark_conf.spark.sql.adaptive.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.sql.adaptive.coalescePartitions.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.databricks.delta.optimizeWrite.enabled" : {
      "type" : "fixed",
      "value" : "true"
    }
  })
}

# ==============================================================================
# 2. SKEW - Data Distribution Optimization
# ==============================================================================

resource "databricks_cluster_policy" "skew_handling" {
  name = "Skew Handling - AQE Policy"

  definition = jsonencode({
    "spark_conf.spark.sql.adaptive.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.sql.adaptive.skewJoin.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.sql.adaptive.skewJoin.skewedPartitionFactor" : {
      "type" : "fixed",
      "value" : "5"
    },
    "spark_conf.spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : {
      "type" : "fixed",
      "value" : "256MB"
    },
    "spark_conf.spark.sql.autoBroadcastJoinThreshold" : {
      "type" : "fixed",
      "value" : "50MB"
    }
  })
}

# ==============================================================================
# 3. SHUFFLE - Network Optimization
# ==============================================================================

resource "databricks_cluster_policy" "shuffle_optimized" {
  name = "Shuffle Optimized - Network Efficiency Policy"

  definition = jsonencode({
    "spark_conf.spark.sql.shuffle.partitions" : {
      "type" : "range",
      "minValue" : 100,
      "maxValue" : 400,
      "defaultValue" : 200
    },
    "spark_conf.spark.sql.adaptive.coalescePartitions.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.sql.adaptive.coalescePartitions.minPartitionSize" : {
      "type" : "fixed",
      "value" : "64MB"
    },
    "spark_conf.spark.shuffle.compress" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.io.compression.codec" : {
      "type" : "fixed",
      "value" : "snappy"
    },
    "spark_conf.spark.shuffle.service.enabled" : {
      "type" : "fixed",
      "value" : "true"
    }
  })
}

# ==============================================================================
# 4. STORAGE - I/O Optimization
# ==============================================================================

resource "databricks_cluster_policy" "storage_optimized" {
  name = "Storage I/O Optimized - Delta Policy"

  definition = jsonencode({
    "spark_conf.spark.databricks.delta.optimizeWrite.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.databricks.delta.autoCompact.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.databricks.delta.properties.defaults.autoOptimize.optimizeWrite" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.databricks.delta.properties.defaults.autoOptimize.autoCompact" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.databricks.io.cache.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.sql.files.maxPartitionBytes" : {
      "type" : "fixed",
      "value" : "128MB"
    },
    "enable_photon" : {
      "type" : "fixed",
      "value" : true
    }
  })
}

# ==============================================================================
# 5. SERIALIZATION - CPU Optimization
# ==============================================================================

resource "databricks_cluster_policy" "serialization_optimized" {
  name = "Serialization Optimized - CPU Efficiency Policy"

  definition = jsonencode({
    "spark_conf.spark.serializer" : {
      "type" : "fixed",
      "value" : "org.apache.spark.serializer.KryoSerializer"
    },
    "spark_conf.spark.kryoserializer.buffer.max" : {
      "type" : "fixed",
      "value" : "512m"
    },
    "spark_conf.spark.sql.codegen.wholeStage" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.sql.codegen.factoryMode" : {
      "type" : "fixed",
      "value" : "CODEGEN_ONLY"
    },
    "enable_photon" : {
      "type" : "fixed",
      "value" : true
    }
  })
}

# ==============================================================================
# Combined "5 S" Optimized Policy
# ==============================================================================

resource "databricks_cluster_policy" "five_s_optimized" {
  name = "5S Framework - All Optimizations Combined"

  definition = jsonencode({
    # SPILL - Memory Management
    "spark_conf.spark.memory.fraction" : {
      "type" : "fixed",
      "value" : "0.8"
    },
    "spark_conf.spark.memory.storageFraction" : {
      "type" : "fixed",
      "value" : "0.3"
    },

    # SKEW - Data Distribution
    "spark_conf.spark.sql.adaptive.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.sql.adaptive.skewJoin.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.sql.adaptive.skewJoin.skewedPartitionFactor" : {
      "type" : "fixed",
      "value" : "5"
    },

    # SHUFFLE - Network Optimization
    "spark_conf.spark.sql.shuffle.partitions" : {
      "type" : "range",
      "minValue" : 100,
      "maxValue" : 400,
      "defaultValue" : 200
    },
    "spark_conf.spark.sql.adaptive.coalescePartitions.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },

    # STORAGE - I/O Optimization
    "spark_conf.spark.databricks.delta.optimizeWrite.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.databricks.delta.autoCompact.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },
    "spark_conf.spark.databricks.io.cache.enabled" : {
      "type" : "fixed",
      "value" : "true"
    },

    # SERIALIZATION - CPU Optimization
    "spark_conf.spark.serializer" : {
      "type" : "fixed",
      "value" : "org.apache.spark.serializer.KryoSerializer"
    },
    "spark_conf.spark.kryoserializer.buffer.max" : {
      "type" : "fixed",
      "value" : "512m"
    },

    # Photon for all workloads
    "enable_photon" : {
      "type" : "fixed",
      "value" : true
    },

    # Autotermination for cost optimization
    "autotermination_minutes" : {
      "type" : "range",
      "minValue" : 10,
      "maxValue" : 120,
      "defaultValue" : 20
    }
  })
}

# Grant policy access to groups
resource "databricks_permissions" "five_s_policy" {
  cluster_policy_id = databricks_cluster_policy.five_s_optimized.id

  access_control {
    group_name       = databricks_group.data_engineers.display_name
    permission_level = "CAN_USE"
  }

  depends_on = [databricks_cluster_policy.five_s_optimized]
}

# Output policy IDs for reference
output "performance_policies" {
  description = "Performance tuning cluster policy IDs"
  value = {
    memory_optimized        = databricks_cluster_policy.memory_optimized.id
    skew_handling           = databricks_cluster_policy.skew_handling.id
    shuffle_optimized       = databricks_cluster_policy.shuffle_optimized.id
    storage_optimized       = databricks_cluster_policy.storage_optimized.id
    serialization_optimized = databricks_cluster_policy.serialization_optimized.id
    five_s_combined         = databricks_cluster_policy.five_s_optimized.id
  }
}
